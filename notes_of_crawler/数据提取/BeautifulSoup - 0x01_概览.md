# BeautifulSoup - æ¦‚è§ˆ

> GitHub@[orca-j35](https://github.com/orca-j35)ï¼Œæ‰€æœ‰ç¬”è®°å‡æ‰˜ç®¡äº [python_notes](https://github.com/orca-j35/python_notes) ä»“åº“

## æ¦‚è¿°

âš å®˜æ–¹æ–‡æ¡£ä¸­æ··æ‚äº† Py2 å’Œ Py3 çš„æœ¯è¯­å’Œä»£ç ï¼Œæœ¬ç¬”è®°é’ˆå¯¹ Py3 æ¢³ç†äº†æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œåœ¨äº†è§£ BeautifulSoup çš„è¿‡ç¨‹ä¸­ï¼Œå»ºè®®å°†æœ¬ç¬”è®°ä¸å®˜æ–¹æ–‡æ¡£é…åˆé£Ÿç”¨ã€‚

[Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) æ˜¯ä¸€ä¸ªç”¨æ¥ä» HTML æˆ– XML æ–‡ä»¶ä¸­æå–æ•°æ®çš„ Python åº“ã€‚åœ¨ä½¿ç”¨ BeautifulSoup æ—¶ï¼Œæˆ‘ä»¬é€‰æ‹©è‡ªå·±å–œæ¬¢çš„è§£æå™¨ï¼Œä»è€Œä»¥è‡ªå·±ç†Ÿæ‚‰çš„æ–¹å¼æ¥å¯¼èˆªã€æŸ¥æ‰¾å’Œä¿®æ”¹è§£ææ ‘ã€‚

ç›¸å…³èµ„æº:

- Home: https://www.crummy.com/software/BeautifulSoup/
- PyPI: https://pypi.org/project/beautifulsoup4/
- Docs-EN: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- Docs-CN: https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/

å®‰è£…:

```shell
pip install beautifulsoup4
```

å¦‚æœé‡åˆ°å®‰è£…é—®é¢˜ï¼Œå¯ä»¥å‚è€ƒ:

- [Installing Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup)
- [Problems after installation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#problems-after-installation)

å¦‚æœèƒ½é¡ºåˆ©æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼Œåˆ™è¯´æ˜å®‰è£…æˆåŠŸ:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<p>Hello</p>', 'lxml')
print(soup.p.string) #> Hello
```

âš åœ¨å®‰è£…åº“å’Œå¯¼å…¥åº“æ—¶ä½¿ç”¨çš„åç§°ä¸ä¸€å®šç›¸åŒï¼Œä¾‹å¦‚: åœ¨å®‰è£… BeautifulSoup4 æ—¶ï¼Œä½¿ç”¨çš„åç§°æ˜¯ `beautifulsoup4`ï¼›åœ¨å¯¼å…¥æ—¶ï¼Œä½¿ç”¨çš„åç§°æ˜¯ `bs4` (è·¯å¾„ä¸º `~\Python\Lib\site-packages\bs4`)ã€‚

å¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°æœ¬æ–‡æœªæ¶µç›–çš„é—®é¢˜ï¼Œè¯·å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#troubleshooting

### Three sisters

ä¸‹é¢è¿™æ®µåä¸º "Three sisters" æ–‡æ¡£æ˜¯æœ¬ç¬”è®°çš„ HTML ç¤ºä¾‹æ–‡æ¡£(å®˜æ–¹æ–‡æ¡£ä¸­ä¹Ÿç”¨çš„è¿™æ®µä»£ç ):

```html
html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""
```

è¿™æ®µ HTML æ–‡æ¡£å­˜åœ¨ "tag soup"ï¼ŒHTML è§£æå™¨ä¼šè‡ªåŠ¨ä¿®å¤ "tag soup"

### æé«˜æ€§èƒ½

BeautifulSoup çš„é€Ÿåº¦æ°¸è¿œä¼šä½äºå…¶ä½¿ç”¨çš„è§£æå™¨çš„é€Ÿåº¦ã€‚å¦‚æœå¯¹é€Ÿåº¦æœ‰ä¸¥æ ¼è¦æ±‚ï¼Œåº”ç›´æ¥ä½¿ç”¨ lxml åº“æ¥è§£æã€‚

å¯¹ BeautifulSoup è€Œè¨€ï¼Œlxml è§£æå™¨çš„é€Ÿåº¦æ¯” html.parser æˆ– html5lib æ›´å¿«ã€‚

å¯ä»¥é€šè¿‡å®‰è£… [cchardet](http://pypi.python.org/pypi/cchardet/) åº“æ¥æ˜¾è‘—æå‡æ£€æµ‹ç¼–ç æ–¹æ¡ˆçš„é€Ÿåº¦ã€‚

[ä»…è§£æéƒ¨åˆ†æ–‡æ¡£](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parsing-only-part-of-a-document)å¹¶ä¸ä¼šèŠ‚çœå¤§é‡çš„è§£ææ—¶é—´ï¼Œä½†æ˜¯å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ï¼Œå¹¶æœ‰æ•ˆæå‡æ£€ç´¢æ–‡æ¡£çš„é€Ÿåº¦ã€‚

### å¯¹è±¡çš„æ˜¯å¦ç›¸ç­‰

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#copying-beautiful-soup-objects

Beautiful Soup says that two `NavigableString` or `Tag` objects are equal when they represent the same HTML or XML markup. In this example, the two <b> tags are treated as equal, even though they live in different parts of the object tree, because they both look like â€œ<b>pizza</b>â€:

```
markup = "<p>I want <b>pizza</b> and more <b>pizza</b>!</p>"
soup = BeautifulSoup(markup, 'html.parser')
first_b, second_b = soup.find_all('b')
print first_b == second_b
# True

print first_b.previous_element == second_b.previous_element
# False
```

If you want to see whether two variables refer to exactly the same object, use is:

```
print first_b is second_b
# False
```

### æ‹·è´ BeautifulSoup å¯¹è±¡

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#copying-beautiful-soup-objects

You can use `copy.copy()` to create a copy of any `Tag` or `NavigableString`:

```python
import copy
p_copy = copy.copy(soup.p)
print p_copy
# <p>I want <b>pizza</b> and more <b>pizza</b>!</p>
```

The copy is considered equal to the original, since it represents the same markup as the original, but itâ€™s not the same object:

```python
print soup.p == p_copy
# True

print soup.p is p_copy
# False
```

The only real difference is that the copy is completely detached from the original Beautiful Soup object tree, just as if `extract()` had been called on it:

```python
print p_copy.parent
# None
```

This is because two different `Tag` objects canâ€™t occupy the same space at the same time.

## BeautifulSoup()ğŸ› 

> ğŸ› BeautifulSoup(self, markup="", features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, \*\*kwargs)
>

æ„é€ å™¨ `BeautifulSoup()` ä¸­å„å‚æ•°çš„å«ä¹‰å¦‚ä¸‹:

- `markup` - è¦è§£æçš„æ ‡ç­¾(*markup*)ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ– file-like å¯¹è±¡ã€‚

  ```python
  from bs4 import BeautifulSoup
  
  with open("index.html") as fp:
      soup = BeautifulSoup(fp)
  
  soup = BeautifulSoup("<html>data</html>")
  ```

- `features` - ç”¨æ¥è®¾ç½®è§£æå™¨ï¼Œå¯ä½¿ç”¨è§£æå™¨çš„åç§°("lxml", "lxml-xml", "html.parser", "html5lib")ï¼Œæˆ–ä½¿ç”¨æ ‡ç­¾çš„ç±»å‹("html", "html5", "xml")ã€‚å»ºè®®æ˜ç¡®ç»™å‡ºéœ€è¦ä½¿ç”¨çš„è§£æå™¨ï¼Œä»¥ä¾¿ BeautifulSoup åœ¨ä¸åŒçš„å¹³å°å’Œè™šæ‹Ÿç¯å¢ƒä¸­æä¾›ç›¸åŒçš„ç»“æœã€‚

  é»˜è®¤æƒ…å†µä¸‹ï¼ŒBeautifulSoup ä¼šä»¥ HTML æ ¼å¼è§£ææ–‡æ¡£ï¼Œå¦‚æœè¦ä»¥ XML æ ¼å¼è§£ææ–‡æ¡£ï¼Œåˆ™éœ€è®¾ç½® `features='xml'`ã€‚ç›®å‰æ”¯æŒè§£æ XML çš„è§£æå™¨ä»…æœ‰ lxmlã€‚

  å¦‚æœæ²¡æœ‰æ‰‹åŠ¨è®¾ç½®è§£æå™¨ï¼ŒBeautifulSoup å°†ä¼šåœ¨å·²å®‰è£…çš„è§£æå™¨ä¸­é€‰ä¸€ä¸ªæœ€å¥½ç”¨çš„ HTML è§£æå™¨ï¼Œè§£æå™¨çš„ä¼˜å…ˆçº§ä¾æ¬¡æ˜¯ lxmlâ€™s HTML parser > html5lib's parser > Pythonâ€™s html.parserã€‚

  å¦‚æœå·²æ‰‹åŠ¨è®¾ç½®æŸè§£æå™¨ï¼Œä½†æ˜¯å¹¶ä¸ºå®‰è£…è¯¥è§£æå™¨ï¼ŒBeautifulSoup å°†å¿½ç•¥è¯¥è®¾ç½®å¹¶æŒ‰ç…§ä¼˜å…ˆçº§é€‰æ‹©ä¸€ä¸ªè§£æå™¨ã€‚

- `builder` - ä¸éœ€è¦ä½¿ç”¨çš„å‚æ•°(A specific TreeBuilder to use instead of looking one up based on `features`)ã€‚

- `parse_only` - ä»¥ SoupStrainer å¯¹è±¡ä½œä¸ºå®å‚å€¼ã€‚åœ¨è§£ææ–‡æ¡£çš„è¿‡ç¨‹ä¸­åªä¼šè€ƒè™‘ä¸ SoupStrainer åŒ¹é…çš„éƒ¨åˆ†ã€‚å½“æˆ‘ä»¬åªéœ€è¦è§£ææŸéƒ¨åˆ†æ–‡æ¡£æ—¶éå¸¸æœ‰ç”¨ï¼Œæ¯”å¦‚ç”±äºæ–‡æ¡£å¤ªå¤§è€Œæ— æ³•æ”¾å…¨éƒ¨æ”¾å…¥å†…å­˜æ—¶ï¼Œä¾¿å¯ä»¥è€ƒè™‘åªè§£ææŸéƒ¨åˆ†æ–‡æ¡£ã€‚

- `from_encoding` - ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè¢«è§£æçš„æ–‡æ¡£çš„ç¼–ç ã€‚å¦‚æœ BeautifulSoup åœ¨çŒœæµ‹æ–‡æ¡£ç¼–ç æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ä¼ é€’æ­¤å‚æ•°ã€‚

- `exclude_encodings` - ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè¡¨ç¤ºå·²çŸ¥çš„é”™è¯¯ç¼–ç ã€‚å¦‚æœä½ ä¸çŸ¥é“æ–‡æ¡£ç¼–ç ï¼Œä½†ä½ çŸ¥é“ BeautifulSoup çš„çŒœæµ‹å‡ºç°é”™è¯¯æ—¶ï¼Œè¯·ä¼ é€’æ­¤å‚æ•°ã€‚

- `**kwargs` - ä¸ºäº†ä¿è¯å‘åå…¼å®¹ï¼Œæ„é€ å¯æ¥å— BeautifulSoup3 ä¸­ä½¿ç”¨çš„æŸäº›å…³é”®å­—å‚æ•°ï¼Œä½†è¿™äº›å…³é”®å­—å‚æ•°åœ¨ BeautifulSoup4 ä¸­å¹¶ä¸ä¼šæ‰§è¡Œä»»ä½•æ“ä½œã€‚



### è§£æå™¨

Beautiful Soup æ”¯æŒ Python æ ‡å‡†åº“ä¸­çš„ HTML [è§£æå™¨](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#id9)ï¼ŒåŒæ—¶è¿˜æ”¯æŒä¸€äº›ç¬¬ä¸‰æ–¹çš„è§£æå™¨(å¦‚ [lxml](http://lxml.de/)):

- Pythonâ€™s html.parser - `BeautifulSoup(markup,"html.parser")`
- lxmlâ€™s HTML parser - `BeautifulSoup(markup, "lxml")`
- lxmlâ€™s XML parser - `BeautifulSoup(markup, "lxml-xml")` æˆ– `BeautifulSoup(markup, "xml")`
- html5lib - `BeautifulSoup(markup, "html5lib")`

é»˜è®¤æƒ…å†µä¸‹ï¼ŒBeautifulSoup ä¼šä»¥ HTML æ ¼å¼è§£ææ–‡æ¡£ï¼Œå¦‚æœè¦ä»¥ XML æ ¼å¼è§£ææ–‡æ¡£ï¼Œåˆ™éœ€è®¾ç½® `features='xml'`ã€‚ç›®å‰æ”¯æŒè§£æ XML çš„è§£æå™¨ä»…æœ‰ lxmlã€‚

å¦‚æœæ²¡æœ‰æ‰‹åŠ¨è®¾ç½®è§£æå™¨ï¼ŒBeautifulSoup å°†ä¼šåœ¨å·²å®‰è£…çš„è§£æå™¨ä¸­é€‰ä¸€ä¸ªæœ€å¥½ç”¨çš„ HTML è§£æå™¨ï¼Œè§£æå™¨çš„ä¼˜å…ˆçº§ä¾æ¬¡æ˜¯ lxmlâ€™s HTML parser > html5lib's parser > Pythonâ€™s html.parserã€‚

å¦‚æœå·²æ‰‹åŠ¨è®¾ç½®æŸè§£æå™¨ï¼Œä½†æ˜¯å¹¶ä¸ºå®‰è£…è¯¥è§£æå™¨ï¼ŒBeautifulSoup å°†å¿½ç•¥è¯¥è®¾ç½®å¹¶æŒ‰ç…§ä¼˜å…ˆçº§é€‰æ‹©ä¸€ä¸ªè§£æå™¨ã€‚

ç¬¬ä¸‰æ–¹è§£æå™¨çš„å®‰è£…æ–¹æ³•å’Œä¼˜ç¼ºç‚¹å¯¹æ¯”: [Installing a parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser)

å»ºè®®ä½¿ç”¨ lxml è§£æå™¨æ¥æé«˜è§£æé€Ÿåº¦ã€‚æ—©äº 2.7.3 å’Œ 3.2.2 çš„ Python ç‰ˆæœ¬ï¼Œå¿…é¡»ä½¿ç”¨ lxml å’Œ html5lib è§£æå™¨ï¼Œå› ä¸ºè¿™äº›ç‰ˆæœ¬çš„å†…ç½® HTML è§£æå™¨ä¸å¤Ÿç¨³å®šã€‚

Note: å¦‚æœè¯•å›¾è§£ææ— æ•ˆçš„ HTML/XML æ–‡æ¡£ï¼Œä¸åŒè§£æå™¨å¯èƒ½ä¼šç»™å‡ºä¸åŒçš„ç»“æœã€‚

æœ‰å…³è§£æå™¨é—´çš„å…·ä½“å·®å¼‚ï¼Œè¯¦è§: [Specifying the parser to use](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use)

### è§£æ XML æ–‡æ¡£

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parsing-xml

é»˜è®¤æƒ…å†µä¸‹ï¼ŒBeautifulSoup ä¼šä»¥ HTML æ ¼å¼è§£ææ–‡æ¡£ï¼Œå¦‚æœè¦ä»¥ XML æ ¼å¼è§£ææ–‡æ¡£ï¼Œåˆ™éœ€è®¾ç½® `features='xml'`ã€‚ç›®å‰æ”¯æŒè§£æ XML çš„è§£æå™¨ä»…æœ‰ lxmlã€‚

### ç¼–ç 

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#encodings

HTML æˆ– XML æ–‡æ¡£å¯èƒ½ä¼šé‡‡ç”¨ä¸åŒçš„ç¼–ç æ–¹æ¡ˆ(å¦‚ ASCII æˆ– UTF-8)ï¼Œå½“ä½ å°†æ–‡æ¡£åŠ è½½åˆ° BeautifulSoup åï¼Œä¾¿ä¼šè‡ªåŠ¨è½¬æ¢ä¸º Unicodeã€‚

```python
markup = "<h1>Sacr\xc3\xa9 bleu!</h1>"
soup = BeautifulSoup(markup, 'lxml')
print(soup.h1)
#> <h1>SacrÃ© bleu!</h1>
print(soup.h1.string)
#> u'Sacr\xe9 bleu!'
```

BeautifulSoup ä¼šä½¿ç”¨ä¸€ä¸ªå«åš [Unicode, Dammit](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#unicode-dammit) çš„å­åº“æ¥æ£€æµ‹æ–‡æ¡£ç¼–ç å¹¶å°†å…¶è½¬æ¢ä¸º Unicodeã€‚ `BeautifulSoup` å¯¹è±¡çš„ `.original_encoding` å±æ€§è®°å½•äº†è‡ªåŠ¨è¯†åˆ«ç¼–ç çš„ç»“æœ:

```python
print(soup.original_encoding)
#> 'utf-8'
```

åœ¨å¤§å¤šæ•°æ—¶å€™ï¼ŒUnicode, Dammit èƒ½å¤ŸçŒœæµ‹å‡ºæ­£ç¡®çš„ç¼–ç æ–¹æ¡ˆï¼Œä½†æ˜¯å¶å°”ä¹Ÿä¼šçŠ¯é”™ã€‚æœ‰æ—¶å€™å³ä¾¿çŒœæµ‹æ­£ç¡®ï¼Œä½†ä¹Ÿéœ€è¦å…ˆé€å­—èŠ‚éå†æ–‡æ¡£åæ‰èƒ½ç»™å‡ºç­”æ¡ˆï¼Œè¿™æ ·éå¸¸è€—æ—¶ã€‚å¦‚æœä½ çŸ¥é“æ–‡æ¡£çš„ç¼–ç æ–¹æ¡ˆï¼Œåˆ™å¯ä»¥é€šè¿‡ `from_encoding` å‚æ•°æ¥è®¾ç½®ç¼–ç æ–¹æ¡ˆï¼Œä»è€Œé¿å…é”™è¯¯å’Œå»¶è¿Ÿã€‚

> Hereâ€™s a document written in ISO-8859-8. The document is so short that Unicode, Dammit canâ€™t get a lock on it, and misidentifies it as ISO-8859-7:
>
> ```python
> markup = b"<h1>\xed\xe5\xec\xf9</h1>"
> soup = BeautifulSoup(markup)
> soup.h1
> <h1>Î½ÎµÎ¼Ï‰</h1>
> soup.original_encoding
> 'ISO-8859-7'
> ```
>
> We can fix this by passing in the correct `from_encoding`:
>
> ```python
> soup = BeautifulSoup(markup, from_encoding="iso-8859-8")
> soup.h1
> <h1>××•×œ×©</h1>
> soup.original_encoding
> 'iso8859-8'
> ```

å¦‚æœä½ å¹¶ä¸çŸ¥é“ç¼–ç æ–¹æ¡ˆï¼Œä½†æ˜¯ä½ çŸ¥é“ Unicode, Dammit ç»™å‡ºäº†é”™è¯¯ç­”æ¡ˆï¼Œåˆ™å¯ä»¥ä½¿ç”¨ `exclude_encodings` å‚æ•°æ¥æ’é™¤æŸäº›ç¼–ç æ–¹æ¡ˆ:

> ```
> soup = BeautifulSoup(markup, exclude_encodings=["ISO-8859-7"])
> soup.h1
> <h1>××•×œ×©</h1>
> soup.original_encoding
> 'WINDOWS-1255'
> ```
>
> Windows-1255 isnâ€™t 100% correct, but that encoding is a compatible superset of ISO-8859-8, so itâ€™s close enough. (`exclude_encodings` is a new feature in Beautiful Soup 4.4.0.)

å¦‚æœéœ€è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·é˜…è¯»: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#encodings



### ä»…è§£æéƒ¨åˆ†æ–‡æ¡£

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parsing-only-part-of-a-document

å¯¹äºä»…éœ€è¦è§£æ `<a>` æ ‡ç­¾æƒ…å†µè€Œè¨€ï¼Œå…ˆè§£ææ•´ä¸ªæ–‡æ¡£ç„¶åå†æŸ¥æ‰¾ `<a>` æ ‡ç­¾æ ‡å‡†è¿‡ç¨‹ä¼šæµªè´¹å¤§é‡çš„æ—¶é—´å’Œå†…å­˜ã€‚å¦‚æœä¸€å¼€å§‹å°±å¿½ç•¥æ‰ä¸ `<a>` æ ‡ç­¾æ— å…³çš„éƒ¨åˆ†ï¼Œåˆ™ä¼šæœ‰æ•ˆæå‡æŸ¥è¯¢é€Ÿåº¦ã€‚

å¯¹äºä»…éœ€è¦è§£æéƒ¨åˆ†æ–‡æ¡£çš„æƒ…å†µè€Œè¨€ï¼Œå¯ä½¿ç”¨ `SoupStrainer` ç±»ç­›é€‰å‡ºè¦ä¿ç•™çš„æ ‡ç­¾ã€‚

âš [ä»…è§£æéƒ¨åˆ†æ–‡æ¡£](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parsing-only-part-of-a-document)å¹¶ä¸ä¼šèŠ‚çœå¤§é‡çš„è§£ææ—¶é—´ï¼Œä½†æ˜¯å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ï¼Œå¹¶æœ‰æ•ˆæå‡æ£€ç´¢æ–‡æ¡£çš„é€Ÿåº¦ã€‚

âš html5lib è§£æå™¨ä¸æ”¯æŒè¯¥åŠŸèƒ½ï¼ŒåŸå› å¦‚ä¸‹:

> If you use html5lib, the whole document will be parsed, no matter what. This is because html5lib constantly rearranges the parse tree as it works, and if some part of the document didnâ€™t actually make it into the parse tree, itâ€™ll crash. To avoid confusion, in the examples below Iâ€™ll be forcing Beautiful Soup to use Pythonâ€™s built-in parser.

#### SoupStrainerğŸ˜

`SoupStrainer()` æ„é€ å™¨çš„å‚æ•°ä¸[æœç´¢è§£ææ ‘çš„æ–¹æ³•](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)ç›¸åŒ: [name](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#id11), [attrs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#attrs), [text](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#id12), [**kwargs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kwargs)ï¼Œä¸å¯å°† text å†™ä½œ stringï¼Œå¯¹ `SoupStrainer()` è€Œè¨€ text å’Œ string ä¸èƒ½ç­‰æ•ˆä½¿ç”¨ã€‚

ç¤ºä¾‹ - `SoupStrainer` å¯¹è±¡çš„ä½¿ç”¨æ–¹æ³•:

```python
from bs4 import SoupStrainer

html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>
"""
only_a_tags = SoupStrainer("a")
soup = BeautifulSoup(html_doc, "html.parser", parse_only=only_a_tags)
print([f'{type(i)}::{i.name}' for i in soup])
#> ["<class 'bs4.element.Tag'>::a", "<class 'bs4.element.Tag'>::a", "<class 'bs4.element.Tag'>::a"]


only_tags_with_id_link2 = SoupStrainer(id="link2")
soup = BeautifulSoup(
    html_doc, "html.parser", parse_only=only_tags_with_id_link2)
print([f'{type(i)}::{i}' for i in soup])
#> ['<class \'bs4.element.Tag\'>::<a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>']


def is_short_string(text: str):
    return len(text) < 10
only_short_strings = SoupStrainer(text=is_short_string)
soup = BeautifulSoup(html_doc, "html.parser", parse_only=only_short_strings)
print([repr(i) for i in soup])
#> ["'\\n'", "'\\n'", "'\\n'", "'\\n'", "'Elsie'", "',\\n'", "'Lacie'", "' and\\n'", "'Tillie'", "'\\n'", "'...'", "'\\n'"]
```

`SoupStrainer` å¯ç”¨ä½œ[æœç´¢è§£ææ ‘çš„æ–¹æ³•](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)çš„å‚æ•°ï¼Œè¿™å¯èƒ½å¹¶ä¸å¸¸è§ï¼Œä½†è¿˜æ˜¯æä¸€ä¸‹:

```python
def is_short_string(text: str):
    return len(text) < 10


only_short_strings = SoupStrainer(text=is_short_string)
soup = BeautifulSoup(
    html_doc,
    "html.parser",
)
print([repr(i) for i in soup.find_all(only_short_strings)])
#> "'\\n'", "'\\n'", "'\\n'", "'\\n'", "'Elsie'", "',\\n'", "'Lacie'", "' and\\n'", "'Tillie'", "'\\n'", "'...'", "'\\n'"]
```



## å¯¹è±¡çš„ç§ç±»

> å‚è€ƒ: [Kinds of objects](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects)

BeautifulSoup ä¼šå°†å¤æ‚çš„ HTML æ–‡æ¡£è½¬æ¢ä¸ºå¤æ‚çš„ Python å¯¹è±¡æ ‘ï¼Œæ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä¸€ä¸ª Python å¯¹è±¡ï¼Œå…±æœ‰å››ç§éœ€è¦å¤„ç†å¯¹è±¡: `Tag`, `NavigableString`, `BeautifulSoup`, `Comment`

### Tag ğŸ˜

`Tag` å¯¹è±¡å¯¹åº”äºåŸå§‹æ–‡æ¡£ä¸­çš„ XML æˆ– HTML æ ‡è®°(tag)ã€‚

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
print(type(tag))
# <class 'bs4.element.Tag'>
```

`Tag` å¯¹è±¡æ‹¥æœ‰å¾ˆå¤šå±æ€§å’Œæ–¹æ³•ï¼Œåœ¨ [Navigating the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree) å’Œ [Searching the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) ä¸­æœ‰è¯¦ç»†è§£é‡Šã€‚æœ¬å°èŠ‚ä»…ä»‹ç» `Tag` å¯¹è±¡ä¸¤ä¸ªæœ€é‡è¦çš„ç‰¹æ€§ã€‚

#### name

æ¯ä¸ª `Tag` å¯¹è±¡éƒ½æœ‰è‡ªå·±çš„åå­—ï¼Œé€šè¿‡ `.name` å­—æ®µè®¿é—®:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
print(tag.name)
#> b
```

å¦‚æœä¿®æ”¹äº† `Tag` å¯¹è±¡çš„ `.name` å­—æ®µï¼Œåˆ™ä¼šå½±å“ `BeautifulSoup` å¯¹è±¡ç”Ÿæˆçš„ HTML æ–‡æ¡£:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
tag.name = "blockquote"
print(tag)
#> <blockquote class="boldest">Extremely bold</blockquote>
print(soup)
#> <html><body><blockquote class="boldest">Extremely bold</blockquote></body></html>
```



#### Attributes

ä¸€ä¸ª HTML æ ‡ç­¾å¯åŒ…å«ä»»æ„æ•°é‡çš„å±æ€§(*attributes*)ã€‚ä¾‹å¦‚ï¼Œæ ‡ç­¾ `<b id="boldest">` åŒ…å«åä¸º `"id"` çš„å±æ€§ï¼Œå…¶å€¼ä¸º `"boldest"`ã€‚

å¯å°† `Tag` å¯¹è±¡è§†ä½œå­˜æ”¾æ ‡ç­¾å±æ€§çš„å­—å…¸ï¼Œé”®å€¼å¯¹ç”±å±æ€§åå’Œå±æ€§å€¼æ„æˆï¼Œä½¿ç”¨æ–¹æ³•ä¹Ÿä¸å­—å…¸ç›¸åŒã€‚å¦å¤–ï¼Œè¿˜å¯é€šè¿‡ `.attrs` å­—æ®µæ¥è·å–å­˜æ”¾æ ‡ç­¾å±æ€§çš„å­—å…¸ã€‚

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b id="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
print(tag['id'])  #> boldest
print(tag.get('id'))  #> boldest
print(tag.attrs) #> {'id': 'boldest'}
```

`Tag` å¯¹è±¡æ”¯æŒå¯¹æ ‡ç­¾çš„å±æ€§è¿›è¡Œæ·»åŠ ã€åˆ é™¤ã€ä¿®æ”¹:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b id="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
tag['id'] = 'verybold'
tag['another-attribute'] = 1
print(tag)
#> <b another-attribute="1" id="verybold">Extremely bold</b>
del tag['id']
del tag['another-attribute']
print(tag)
#> <b>Extremely bold</b>
print(tag.get('id', "Don't have"))
#> Don't have
print(tag['id']
#> KeyError: 'id'
```

`.has_attr()` æ–¹æ³•ç”¨äºåˆ¤æ–­ `Tag` å¯¹è±¡æ˜¯å¦åŒ…å«æŸä¸ªå±æ€§:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b id="boldest">Extremely bold</b>', 'lxml')
print(soup.b.has_attr('id'))
#> True
print(soup.b.has_attr('class'))
#> False
```



#### Multi-valued attributes

HTML 4 ä¸­æŸäº›å±æ€§å¯ä»¥å…·å¤‡å¤šä¸ªå€¼ï¼ŒHTML 5 åœ¨ HTML 4 çš„åŸºç¡€ä¸Šåˆ é™¤äº†ä¸€äº›å¤šå€¼å±æ€§ï¼Œä½†åˆå¼•å…¥äº†ä¸€äº›å¤šå€¼å±æ€§ã€‚æœ€å¸¸è§çš„å¤šå€¼å±æ€§æ˜¯ `class` (HTML æ ‡ç­¾å¯æŒæœ‰å¤šä¸ª CSS ç±»)ï¼Œå…¶å®ƒä¸€äº›å¤šå€¼å±æ€§çš„ä¾‹å­: `rel`, `rev`, `accept-charset`, `headers`, `accesskey`ã€‚

BeautifulSoup å°†å¤šå€¼å±æ€§çš„å€¼è¡¨ç¤ºä¸ºä¸€ä¸ªåˆ—è¡¨ï¼š

```python
from bs4 import BeautifulSoup
css_soup = BeautifulSoup('<p class="body"></p>', 'lxml')
print(css_soup.p['class'])
#> ["body"]

css_soup = BeautifulSoup('<p class="body strikeout"></p>', 'lxml')
print(css_soup.p['class'])
#> ["body", "strikeout"]
```

å¦‚æœæŸä¸ªå±æ€§çœ‹èµ·æ¥å¥½åƒæœ‰å¤šä¸ªå€¼ï¼Œä½†åœ¨ä»»ä½•ç‰ˆæœ¬çš„ HTML å®šä¹‰ä¸­éƒ½æ²¡æœ‰è¢«å®šä¹‰ä¸ºå¤šå€¼å±æ€§ï¼Œé‚£ä¹ˆ BeautifulSoup ä¼šå°†è¿™ä¸ªå±æ€§ä½œä¸ºå­—ç¬¦ç»„è¿”å›:

```python
id_soup = BeautifulSoup('<p id="my id"></p>', 'lxml')
print(id_soup.p['id'])
#> my id
```

å°† `Tag` è½¬æ¢æˆå­—ç¬¦ä¸²æ—¶ï¼Œä¼šå¯¹å¤šä¸ªå±æ€§å€¼è¿›è¡Œåˆå¹¶:

```python
print(rel_soup.a['rel'])
# ['index']
rel_soup.a['rel'] = ['index', 'contents']
print(rel_soup.p)
# <p>Back to the <a rel="index contents">homepage</a></p>
```

 ``.get_attribute_list()` æ–¹æ³•ç”¨äºè·å–æ ‡ç­¾å±æ€§åˆ—è¡¨ï¼Œæ— è®ºå±æ€§æ˜¯å¦æ˜¯å¤šå€¼å±æ€§éƒ½ä¼šè¿”å›ä¸€ä¸ªåˆ—è¡¨:

```python
id_soup = BeautifulSoup('<p class="body strikeout" id="my id"></p>', 'lxml')
print(id_soup.p['class'])
#> ['body', 'strikeout']
print(id_soup.p.get_attribute_list('class'))
#> ['body', 'strikeout']
print(id_soup.p['id'])
#> my id
print(id_soup.p.get_attribute_list('id'))
#> ['my id']
```

å¦‚æœæ–‡æ¡£ä»¥ XML æ ¼å¼è¿›è¡Œè§£æï¼Œåˆ™ä¸ä¼šåŒ…å«å¤šå€¼å±æ€§:

```python
xml_soup = BeautifulSoup('<p class="body strikeout"></p>', 'xml')
print(xml_soup.p['class'])
#> body strikeout
```

### NavigableString ğŸ˜

`NavigableString` ç»§æ‰¿è‡ª `str` ç±»å’Œ `PageElement` ç±»ï¼Œä¸èƒ½å¯¹ `NavigableString` å¯¹è±¡æ‰€å«å­—ç¬¦ä¸²è¿›è¡Œç¼–è¾‘ï¼Œä½†æ˜¯å¯ä»¥ä½¿ç”¨ `replace_with()` æ–¹æ³•è¿›è¡Œæ›¿æ¢:

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>', 'lxml')
tag = soup.b
tag.string.replace_with("No longer bold")
print(tag)
#> <b class="boldest">No longer bold</b>
```

`NavigableString` æ”¯æŒ  [Navigating the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree) å’Œ [Searching the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) ä¸­æè¿°å¤§éƒ¨åˆ†åŠŸèƒ½ï¼Œä½†å¹¶éå…¨éƒ¨åŠŸèƒ½ã€‚ç”±äº `NavigableString` å¯¹è±¡åªèƒ½åŒ…å«å­—ç¬¦ä¸²ï¼Œä¸èƒ½åŒ…å«å…¶å®ƒå†…å®¹(`Tag` å¯¹è±¡å¯ä»¥åŒ…å«å­—ç¬¦ä¸²æˆ–å­ tag)ï¼Œæ‰€ä»¥ `NavigableString` ä¸æ”¯æŒ `.contents` æˆ– `.string` å­—æ®µï¼Œä¹Ÿä¸æ”¯æŒ `find()` æ–¹æ³•ã€‚åœ¨ `NavigableString` ä¸Šè°ƒç”¨ `name` å­—æ®µæ—¶ï¼Œä¼šè¿”å› `None`

å¦‚æœæƒ³è¦åœ¨ `BeautifulSoup` å¤–éƒ¨ä½¿ç”¨ `NavigableString` ä¸­çš„å­—ç¬¦ä¸²ï¼Œä½ åº”è¯¥å…ˆè°ƒç”¨ `str()` æŠŠ `NavigableString` å¯¹è±¡è½¬æ¢ä¸ºæ™®é€šçš„å­—ç¬¦ä¸²å¯¹è±¡ã€‚å¦‚æœä¸å°†å…¶è½¬æ¢ä¸ºæ™®é€šå­—ç¬¦ä¸²çš„è¯ï¼Œä½ å°†å§‹ç»ˆæŒæœ‰å¯¹æ•´ä¸ª `BeautifulSoup` è§£ææ ‘çš„å¼•ç”¨ï¼Œè¿™ä¼šæµªè´¹å¤§é‡å†…å­˜ã€‚

å¯é€šè¿‡ `.string` å¯¹è±¡è·å– `NavigableString` å¯¹è±¡ï¼Œè¯¦è§ [.stringğŸ”§](#.stringğŸ”§) å°èŠ‚



### BeautifulSoup ğŸ˜

`BeautifulSoup` å¯¹è±¡è¡¨ç¤ºæ•´ä¸ªæ–‡æ¡£ï¼Œåœ¨å¤§éƒ¨åˆ†æ—¶å€™ï¼Œä½ å¯ä»¥å°†å…¶è§†ä¸º `Tag` å¯¹è±¡ã€‚`BeautifulSoup` å¯¹è±¡æ”¯æŒ  [Navigating the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree) å’Œ [Searching the tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) ä¸­æè¿°å¤§éƒ¨åˆ†åŠŸã€‚

ç”±äºå¹¶æ²¡æœ‰ä¸ `BeautifulSoup` å¯¹è±¡å¯¹åº”çš„ HTML/XML tagï¼Œå› æ­¤ `BeautifulSoup` å¯¹è±¡çš„ `name` å­—æ®µä¸º `'[document]'`ï¼Œå¹¶ä¸”ä¸åŒ…å« HTML attributesã€‚

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<b class="boldest">Extremely bold</b>', 'lxml')
print(type(soup))
#> <class 'bs4.BeautifulSoup'>
print(soup.name)
#> [document]
```

### æ³¨é‡ŠåŠç‰¹æ®Šå­—ç¬¦ä¸²

`Tag`, `NavigableString`, `BeautifulSoup` å‡ ä¹æ¶µç›–äº†ä½ åœ¨ HTML æˆ– XML æ–‡ä»¶ä¸­çœ‹åˆ°çš„æ‰€æœ‰å†…å®¹ï¼Œä½†æ˜¯ä»æœ‰ä¸€äº›æ²¡æœ‰è¦†ç›–åˆ°çš„å†…å®¹ï¼Œæ¯”å¦‚æ³¨é‡Š(*comment*):

```python
from bs4 import BeautifulSoup
markup = "<b><!--Hey, buddy. Want to buy a used parser?--></b>"
soup = BeautifulSoup(markup, 'lxml')
comment = soup.b.string
print(type(comment))
#> <class 'bs4.element.Comment'>
print(comment)
#> Hey, buddy. Want to buy a used parser?
```

`Comment` ç±»ç»§æ‰¿è‡ª `PreformattedString`ï¼Œ`PreformattedString` ç»§æ‰¿è‡ª `NavigableString`ã€‚ä¹Ÿå°±æ˜¯è¯´ `Comment` æ˜¯ä¸€ç§ç‰¹æ®Šçš„ `NavigableString` ç±»å‹ã€‚

ä½†æ˜¯å½“æ³¨é‡Šå‡ºç°åœ¨HTMLæ–‡æ¡£ä¸­æ—¶ï¼Œ`Comment` å¯¹è±¡ä¼šä½¿ç”¨ç‰¹æ®Šçš„æ ¼å¼è¾“å‡º:

```python
from bs4 import BeautifulSoup
markup = "<b><!--Hey, buddy. Want to buy a used parser?--></b>"
soup = BeautifulSoup(markup, 'lxml')
print(soup.b.prettify())
'''Out:
<b>
 <!--Hey, buddy. Want to buy a used parser?-->
</b>
'''
```

BeautifulSoup è¿˜ä¸º XML æ–‡æ¡£ä¸­å¯èƒ½ä¼šå‡ºç°çš„å…¶å®ƒå†…å®¹å®šä¹‰äº†å„ç§ç±»: 

- `CData`
- `ProcessingInstruction`
- `Declaration`
- `Doctype`

ä¸ `Comment` ç±»ä¼¼ï¼Œè¿™äº›ç±»éƒ½æ˜¯ `NavigableString` çš„å­ç±»ï¼Œå¹¶è¿›è¡Œäº†ä¸€äº›æ‰©å±•ã€‚ä¸‹é¢è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œå°†ä½¿ç”¨ CDATA block æ¥æ›¿æ¢ `Comment`:

```python
from bs4 import BeautifulSoup
from bs4 import CData
markup = "<b><!--Hey, buddy. Want to buy a used parser?--></b>"
soup = BeautifulSoup(markup, 'lxml')
cdata = CData("A CDATA block")
comment = soup.b.string
comment.replace_with(cdata)
print(soup.b.prettify())
'''Out:
<b>
 <![CDATA[A CDATA block]]>
</b>
'''
```



## è¾“å‡º

> æ‰©å±•é˜…è¯»: [Output encoding](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#output-encoding)

BeautifulSoup å…¼å®¹ Py2 å’Œ Py3 ï¼Œä½† Py2 å’Œ Py3 ä¸­çš„ `str` å¯¹è±¡å¹¶ä¸ç›¸åŒï¼Œè¿™ä¼šå¯¼å‡ºè¾“å‡ºç»“æœå­˜åœ¨å·®å¼‚ï¼Œåœ¨è·å–è¾“å‡ºæ—¶éœ€æ³¨æ„åŒºåˆ†ã€‚

### .decode()ğŸ”¨

è¯¥æ–¹æ³•ä¼šå°† `BeautifulSoup` å¯¹è±¡å’Œ `Tag` å¯¹è±¡ä¸­çš„å†…å®¹è½¬æ¢ä¸º Unicode å­—ç¬¦ä¸²ã€‚

æºä»£ç ä¸­çš„æ³¨é‡Šå¦‚ä¸‹:

```python
def decode(self, indent_level=None,
           eventual_encoding=DEFAULT_OUTPUT_ENCODING,
           formatter="minimal"):
    """Returns a Unicode representation of this tag and its contents.

        :param eventual_encoding: The tag is destined to be
           encoded into this encoding. This method is _not_
           responsible for performing that encoding. This information
           is passed in so that it can be substituted in if the
           document contains a <META> tag that mentions the document's
           encoding.
        """
```

å¯¹ Py3 è€Œè¨€ï¼Œ`decode()` å°†è¿”å› `str` å¯¹è±¡(Uncode å­—ç¬¦ä¸²):

```python
# in Python3
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a>'
soup = BeautifulSoup(markup, 'lxml')
print(type(soup.decode()))
#> <class 'str'>
print(soup.decode())
#> <html><body><a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a></body></html>
```

å¯¹ Py2 è€Œè¨€ï¼Œ`decode()` å°†è¿”å› `Unicode` å¯¹è±¡(Uncode å­—ç¬¦ä¸²):

```python
# in Python2
>>> markup = u'<a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a>'
>>> soup = BeautifulSoup(markup, 'lxml')
>>> print(type(soup.decode()))
<type 'unicode'>
>>> print(soup.decode())
<html><body><a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a></body></html>
```



### .encode()ğŸ”¨

è¯¥æ–¹æ³•ä¼šå…ˆå°†æ•°æ®ç»“æ„è½¬æ¢ä¸º Unicode å­—ç¬¦ä¸²ï¼Œå†æŒ‰ç…§æŒ‡å®šç¼–ç å¯¹ Unicode å­—ç¬¦ä¸²è¿›è¡Œç¼–ç ï¼Œé»˜è®¤é‡‡ç”¨ UTF-8 ç¼–ç ã€‚æºä»£ç å¦‚ä¸‹:

```python
def encode(self, encoding=DEFAULT_OUTPUT_ENCODING,
           indent_level=None, formatter="minimal",
           errors="xmlcharrefreplace"):
    # Turn the data structure into Unicode, then encode the
    # Unicode.
    u = self.decode(indent_level, encoding, formatter)
    return u.encode(encoding, errors)
```

å¯¹ Py3 è€Œè¨€ï¼Œ`encode()` å°†è¿”å›ä»¥ `encoding` ç¼–ç (é»˜è®¤é‡‡ç”¨ UTF-8)çš„ `bytes` å¯¹è±¡:

```python
# in Python3
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a>'
soup = BeautifulSoup(markup, 'lxml')
print(type(soup.encode()))
#> <class 'bytes'>
print(soup.encode())
#> b'<html><body><a href="http://example.com/">\xe8\xbf\x9e\xe6\x8e\xa5\xe5\x88\xb0<i>example.com</i></a></body></html>'
```

å¯¹ Py2 è€Œè¨€ï¼Œ`encode()` å°†è¿”å›ä»¥ `encoding` ç¼–ç (é»˜è®¤é‡‡ç”¨ UTF-8)çš„ `str` å¯¹è±¡(Py2 å’Œ Py3 ä¸­çš„ `str` å¯¹è±¡å¹¶ä¸ç›¸åŒ):

```python
# in Python2
>>> markup = u'<a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a>'
>>> soup = BeautifulSoup(markup, 'lxml')
>>> print(soup.encode())
<html><body><a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a></body></html>
>>> soup.encode()
'<html><body><a href="http://example.com/">\xe8\xbf\x9e\xe6\x8e\xa5\xe5\x88\xb0<i>example.com</i></a></body></html>'
>>> type(soup.encode())
<type 'str'>
```



### .prettify()ğŸ”¨

> å‚è€ƒ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#pretty-printing

ğŸ”¨prettify(self, encoding=None, formatter="minimal")

å½“ `encoding==None` æ—¶ï¼Œ`prettify()` ä¼šå°† BeautifulSoup è§£ææ ‘è½¬æ¢ä¸ºæ ¼å¼è‰¯å¥½çš„ Unicode å­—ç¬¦ä¸²ï¼Œåœ¨å­—ç¬¦ä¸²ä¸­æ¯ä¸ª HTML/XML tag å’Œ å­—ç¬¦ä¸²éƒ½ä¼šç‹¬å ä¸€è¡Œï¼›å½“ `encoding!=None` æ—¶ï¼Œ`prettify()` ä¼šå°† BeautifulSoup è§£ææ ‘ç¼–ç ä¸ºæ ¼å¼è‰¯å¥½çš„ `bytes` å­—ç¬¦ä¸²ã€‚

`prettify()` çš„æºä»£ç å¦‚ä¸‹:

```python
# prettify()çš„æºä»£ç 
def prettify(self, encoding=None, formatter="minimal"):
    if encoding is None:
        return self.decode(True, formatter=formatter)
    else:
        return self.encode(encoding, True, formatter=formatter)
```

ç¤ºä¾‹ - in Py3:

```python
# in Python3
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup, 'lxml')
print(type(soup.prettify()))
#> <class 'str'>
print(soup.prettify())
'''Out:
<html>
 <body>
  <a href="http://example.com/">
   I linked to
   <i>
    example.com
   </i>
  </a>
 </body>
</html>
'''
```

`prettify()` é€‚ç”¨äº `BeautifulSoup` å¯¹è±¡å’Œ `Tag` å¯¹è±¡:

```python
print(soup.a.prettify())
'''Out:
<a href="http://example.com/">
 I linked to
 <i>
  example.com
 </i>
</a>
'''
```

ç¤ºä¾‹ - in Py2:

```python
# in Python2
from bs4 import BeautifulSoup
markup = u'<a href="http://example.com/">è¿æ¥åˆ°<i>example.com</i></a>'
soup = BeautifulSoup(markup, 'lxml')
print(soup.prettify())
'''Out:
<html>
 <body>
  <a href="http://example.com/">
   I linked to
   <i>
    example.com
   </i>
  </a>
 </body>
</html>
'''
```



### formatter å‚æ•°

> å‚è€ƒ: [Output formatters](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#output-formatters)

å¦‚æœä¼ é€’ç»™ `BeautifulSoup()` çš„æ–‡æ¡£ä¸­åŒ…å« HTML å®ä½“(*entities*)ï¼Œé‚£ä¹ˆåœ¨è¾“å‡ºæ–‡æ¡£æ—¶ï¼Œè¿™äº› HTML å®ä½“å°†è¢«è½¬æ¢ä¸º Unicode å­—ç¬¦:

```python
# in Python3
from bs4 import BeautifulSoup
soup = BeautifulSoup("&ldquo;Dammit!&rdquo; he said.", 'lxml')
print(soup)
#> <html><body><p>â€œDammit!â€ he said.</p></body></html>
```

å¦‚æœå°†æ–‡æ¡£ç¼–ç ä¸º `bytes` å¯¹è±¡ï¼Œ`encode()` æ–¹æ³•ä¼šå…ˆå°† HTML æ–‡æ¡£å†…å®¹è½¬æ¢ä¸º Unicode å­—ç¬¦ä¸²(æ­¤æ—¶ HTML å®ä½“å°†è¢«è½¬æ¢ä¸º Unicode å­—ç¬¦)ï¼Œç„¶åå†å°† Unicode å­—ç¬¦ä¸²ç¼–ç ä¸º `bytes` å¯¹è±¡ï¼Œé»˜è®¤é‡‡ç”¨ UTF-8 ç¼–ç ã€‚HTML å®ä½“å°†ä»¥ Unicode å­—ç¬¦çš„å½¢å¼ç¼–ç ã€‚

```python
# in Python3
# æ³¨æ„è§‚å¯ŸHTMLå®ä½“çš„å˜åŒ–
from bs4 import BeautifulSoup
soup = BeautifulSoup("&ldquo;Dammit!&rdquo; he said.", 'lxml')
print(soup.encode())
#> b'<html><body><p>\xe2\x80\x9cDammit!\xe2\x80\x9d he said.</p></body></html>'

print('â€œ'.encode('utf-8'))
#> b'\xe2\x80\x9c'
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨è¾“å‡ºçš„ Unicode å­—ç¬¦ä¸²ä¸­ï¼Œä¸ºäº†ä¿è¯ BeautifulSoup ä¸ä¼šåœ¨æ— æ„ä¸­ç”Ÿæˆæ— æ•ˆçš„ HTML æˆ– XMLï¼Œç‹¬ç«‹çš„ `&`(*ampersand*)å’Œå°–æ‹¬å·ä¼šä»¥ HTML å®ä½“æ˜¾ç¤º:

```python
# ç‹¬ç«‹çš„&ä¼šæ˜¾ç¤ºä¸º&amp;   &amp;ä¼šä¿æŒåŸæ ·
# ç‹¬ç«‹çš„<ä¼šæ˜¾ç¤ºä¸º&lt;    &lt;ä¼šä¿æŒåŸæ ·
# ç‹¬ç«‹çš„>ä¼šæ˜¾ç¤ºä¸º&gt;    &gt;ä¼šä¿æŒåŸæ ·

# in Python3
from bs4 import BeautifulSoup
soup = BeautifulSoup(
    "<p>The law firm of Dewey, Cheatem, > &gt; < &lt; & &amp; Howe</p>",
    'lxml')
p = soup.p
print(p)
#> <p>The law firm of Dewey, Cheatem, &gt; &gt; &lt; &lt; &amp; &amp; Howe</p>
soup = BeautifulSoup(
    '<a href="http://example.com/?foo=val1&bar=val2">A link</a>', 'lxml')
print(soup.a)
#> <a href="http://example.com/?foo=val1&amp;bar=val2">A link</a>
```

å¦‚æœéœ€è¦æ”¹å˜ HTML å®ä½“çš„å‘ˆç°æ–¹å¼ï¼Œä¾¿éœ€è¦å‘ `prettify()` , `encode()` , `decode()` ä¼ é€’ `formatter` å‚æ•°ã€‚`formatter` çš„å®å‚å€¼æœ‰ 6 ç§æƒ…å†µï¼Œé»˜è®¤ä¸º `formatter="minimal"`ã€‚å¦å¤–ï¼Œ`__str__()` , `__unicode__()` , `__repr__()` åœ¨è¾“å‡ºæ—¶åªèƒ½é‡‡ç”¨é»˜è®¤è¡Œä¸ºï¼Œä¸å¯ä¿®æ”¹ã€‚



#### minimal

å½“ `formatter="minimal"` æ—¶ï¼Œä¼šæŒ‰ç…§å‰é¢å™è¿°çš„è§„åˆ™æ¥å¤„ç†å­—ç¬¦ä¸²ï¼Œä»¥ç¡®ä¿ç”Ÿæˆæœ‰æ•ˆçš„ HTML/XML:

```python
# in Python3
from bs4 import BeautifulSoup
french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;</p>"
soup = BeautifulSoup(french, 'lxml')
print(soup.prettify(formatter="minimal"))
'''Out:
<html>
 <body>
  <p>
   Il a dit &lt;&lt;SacrÃ© bleu!&gt;&gt;
  </p>
 </body>
</html>'''
```

#### html

å½“ `formatter="html"` æ—¶ï¼ŒBeautifulSoup ä¼šå°½å¯èƒ½çš„å°† Unicode å­—ç¬¦ä¼ å”¤ä¸º HTML å®ä½“:

```python
# in Python3
from bs4 import BeautifulSoup
french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt; Ã©</p>"
soup = BeautifulSoup(french, 'lxml')
print(soup.prettify(formatter="html"))
'''Out:
<html>
 <body>
  <p>
   Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt; &eacute;
  </p>
 </body>
</html>'''

# If you pass in ``formatter="html5"``, it's the same as
```

#### html5

å½“ `formatter="html5"` æ—¶ï¼ŒBeautifulSoup ä¼šçœç•¥ HTML ç©º tag çš„ç»“æŸæ–œæ ï¼Œä¾‹å¦‚:

```python
# in Python3
from bs4 import BeautifulSoup
soup = BeautifulSoup("<br>", 'lxml')
print(soup.encode(formatter="html"))
# <html><body><br/></body></html>
print(soup.encode(formatter="html5"))
# <html><body><br></body></html>
```

#### None

å½“ `formatter=None` æ—¶ï¼ŒBeautifulSoup å°†ä¸ä¼šåœ¨è¾“å‡ºä¸­ä¿®æ”¹å­—ç¬¦ä¸²ã€‚æ­¤æ—¶çš„è¾“å‡ºé€Ÿåº¦æœ€å¿«ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´ BeautifulSoup ç”Ÿæˆæ— æ•ˆçš„ HTML/XMLï¼Œä¾‹å¦‚:

```python
# in Python3
from bs4 import BeautifulSoup
french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;</p>"
soup = BeautifulSoup(french, 'lxml')
print(soup.prettify(formatter=None))
'''Out:
<html>
 <body>
  <p>
   Il a dit <<SacrÃ© bleu!>>
  </p>
 </body>
</html>
'''

link_soup = BeautifulSoup('<a href="http://example.com/?foo=val1&bar=val2">A link</a>')
print(link_soup.a.encode(formatter=None))
# <a href="http://example.com/?foo=val1&bar=val2">A link</a>
```

#### å‡½æ•°

è¿˜å¯ä»¥å‘ `formatter` ä¼ é€’ä¸€ä¸ªå‡½æ•°ï¼ŒBeautifulSoup ä¼šä¸ºæ–‡æ¡£ä¸­çš„æ¯ä¸ª"å­—ç¬¦ä¸²"å’Œ"å±æ€§å€¼"è°ƒç”¨ä¸€æ¬¡è¯¥å‡½æ•°ã€‚ä½ å¯ä»¥åœ¨è¿™ä¸ªå‡½æ•°ä¸­åšä»»ä½•ä½ æƒ³åšçš„äº‹æƒ…ã€‚ä¸‹é¢è¿™ä¸ª formatter å‡½æ•°ä¼šå°†å­—ç¬¦ä¸²å’Œå±æ€§å€¼è½¬æ¢ä¸ºå¤§å†™ï¼Œå¹¶ä¸ä¼šæ‰§è¡Œå…¶å®ƒæ“ä½œ:

```python
# in Python3
from bs4 import BeautifulSoup

def uppercase(str):
    return str.upper()

french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt;</p>"
soup = BeautifulSoup(french, 'lxml')
print(soup.prettify(formatter=uppercase))
'''Out:
<html>
 <body>
  <p>
   IL A DIT <<SACRÃ‰ BLEU!>>
  </p>
 </body>
</html>'''

link_soup = BeautifulSoup(
    '<a href="http://example.com/?foo=val1&bar=val2">A link</a>', 'lxml')
print(link_soup.a.prettify(formatter=uppercase))
'''Out:
<a href="HTTP://EXAMPLE.COM/?FOO=VAL1&BAR=VAL2">
 A LINK
</a>
'''
```

å¦‚æœä½ æ­£åœ¨ç¼–å†™ formatter å‡½æ•°ï¼Œä½ åº”è¯¥å…ˆäº†è§£ä¸€ä¸‹ `bs4.dammit` æ¨¡å—ä¸­çš„ `EntitySubstitution` ç±»â€”â€”è¯¥ç±»å°† BeautifulSoup ä¸­çš„æ ‡å‡† formatter å®ç°ä¸ºç±»æ–¹æ³•:

- 'html' formatter å¯¹åº”äº `EntitySubstitution.substitute_html`
- 'minimal' formatter å¯¹åº”äº `EntitySubstitution.substitute_xml`

ä½ å¯ä»¥ä½¿ç”¨ä¸Šè¿°å‡½æ•°æ¥æ¨¡æ‹Ÿ `formatter=html` æˆ– `formatter==minimal`ï¼Œå¹¶æ·»åŠ ä¸€äº›ä½ éœ€è¦çš„æ‰©å±•åŠŸèƒ½ã€‚

ä¸‹é¢è¿™ä¸ªç¤ºä¾‹ä¼šå°½å¯èƒ½çš„å°† Unicode å­—ç¬¦ä¼ å”¤ä¸º HTML å®ä½“ï¼Œå¹¶å°†æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¤§å†™:

```python
from bs4 import BeautifulSoup
from bs4.dammit import EntitySubstitution

def uppercase_and_substitute_html_entities(str):
    return EntitySubstitution.substitute_html(str.upper())

french = "<p>Il a dit &lt;&lt;Sacr&eacute; bleu!&gt;&gt; Ã©</p>"
soup = BeautifulSoup(french, 'lxml')
print(soup.prettify(formatter=uppercase_and_substitute_html_entities))
'''Out:
<html>
 <body>
  <p>
   IL A DIT &lt;&lt;SACR&Eacute; BLEU!&gt;&gt; &Eacute;
  </p>
 </body>
</html>
'''
```



### CData å¯¹è±¡

å¦‚æœåˆ›å»ºåˆ›å»ºäº†ä¸€ä¸ª `CData` å¯¹è±¡ï¼Œåˆ™è¯¥å¯¹è±¡å†…çš„æ–‡æœ¬å°†å§‹ç»ˆä¸å…¶æ˜¾ç¤ºå®Œå…¨ä¸€è‡´ï¼Œå¹¶ä¸ä¼šè¿›è¡Œæ ¼å¼åŒ–æ“ä½œã€‚

> Beautiful Soup will call the formatter method, just in case youâ€™ve written a custom method that counts all the strings in the document or something, but it will ignore the return value:

```python
from bs4.element import CData
soup = BeautifulSoup("<a></a>")
soup.a.string = CData("one < three")
print(soup.a.prettify(formatter="xml")) # ?"xml"æ˜¯ä»€ä¹ˆæ„æ€?
# <a>
#  <![CDATA[one < three]]>
# </a>
```



### Non-pretty printing

å¦‚æœåªæƒ³å¾—åˆ°ç»“æœå­—ç¬¦ä¸²ï¼Œå¹¶ä¸”ä¸åœ¨æ„è¾“å‡ºæ ¼å¼ï¼Œåˆ™å¯ä»¥åœ¨ `BeautifulSoup` å¯¹è±¡å’Œ `Tag` å¯¹è±¡ä¸Šè°ƒç”¨ä»¥ä¸‹æ–¹æ³•: 

- `__unicode__()` - å¯¹åº”å†…ç½®å‡½æ•° `unicode()`ï¼Œé€‚ç”¨äº Py2
- `__str__()` - å¯¹åº”å†…ç½®å‡½æ•° `str()`ï¼Œç”±äº Py2 ä¸­çš„ `str` å¯¹è±¡ä¸æ˜¯ Unicode å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥ `str()` åœ¨ Py2 å’Œ Py3 ä¸­çš„è¾“å‡ºå¹¶ä¸ç›¸åŒ
- `__repr__()` - å¯¹åº”äºå†…ç½®å‡½æ•° `repr()`ï¼Œç”±äº Py2 ä¸­çš„ `str` å¯¹è±¡ä¸æ˜¯ Unicode å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥ `repr()` åœ¨ Py2 å’Œ Py3 ä¸­çš„è¾“å‡ºå¹¶ä¸ç›¸åŒ

è¿™ä¸‰ä¸ªæ–¹æ³•çš„æºä»£ç å¦‚ä¸‹:

```python
def __repr__(self, encoding="unicode-escape"):
    """Renders this tag as a string."""
    if PY3K:
        # "The return value must be a string object", i.e. Unicode
        return self.decode()
    else:
        # "The return value must be a string object", i.e. a bytestring.
        # By convention, the return value of __repr__ should also be
        # an ASCII string.
        return self.encode(encoding)

def __unicode__(self):
    return self.decode()

def __str__(self):
    if PY3K:
        return self.decode()
    else:
        return self.encode()

if PY3K:
    __str__ = __repr__ = __unicode__
```

å¯¹ Py3 è€Œè¨€ï¼Œä¸Šè¿°ä¸‰ä¸ªæ–¹æ³•å®Œå…¨ç­‰æ•ˆï¼Œå‡è¿”å› `str` å¯¹è±¡(Unicode å­—ç¬¦ä¸²):

```python
# in Python3
markup = '<a href="http://example.com/">I linked to <i>example.com</i></a>'
soup = BeautifulSoup(markup, 'lxml')
print(soup) # è°ƒç”¨__str__æ–¹æ³•
#> <html><body><a href="http://example.com/">I linked to <i>example.com</i></a></body></html>
```

å¯¹ Py2 è€Œè¨€ï¼Œ`str()` å°†è¿”å›ä»¥ UTF-8 ç¼–ç çš„ `str` å¯¹è±¡(å¦‚æœéœ€è¦äº†è§£ä¸ç¼–ç ç›¸å…³çš„å†…å®¹ï¼Œå¯ä»¥å‚è€ƒ [Encodings](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#encodings) )

```python
# in Python2
>>> markup = u'<a href="http://example.com/">I linked to ç¤ºä¾‹<i>example.com</i></a>'
>>> soup = BeautifulSoup(markup, 'lxml')
>>> str(soup)
'<html><body><a href="http://example.com/">I linked to \xe7\xa4\xba\xe4\xbe\x8b<i>example.com</i></a></body></html>'
```

å¯¹ Py2 è€Œè¨€ï¼Œ`repr()` å°†è¿”å›ä»¥ unicode-escape ç¼–ç (è¯¦è§ [Text Encodings](https://docs.python.org/3.7/library/codecs.html#text-encodings))çš„ `str` å¯¹è±¡:

```python
# in Python2
>>> markup = u'<a href="http://example.com/">I linked to ç¤ºä¾‹<i>example.com</i></a>'
>>> soup = BeautifulSoup(markup, 'lxml')
>>> repr(soup) # ä»¥ASCIIç¼–ç ,å¹¶å°†Unicodeå­—é¢å€¼è¡¨ç¤ºä¸ºquoteå½¢å¼
'<html><body><a href="http://example.com/">I linked to \\u793a\\u4f8b<i>example.com</i></a></body></html>'
```

### .get_text()ğŸ”¨

ğŸ”¨get_text(*self*, *separator*="", *strip*=False, *types*=(NavigableString, CData))

å¦‚æœåªéœ€è¦è·å–æ–‡æ¡£æˆ– tag çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ `get_text()` æ–¹æ³•ï¼Œæºä»£ç å¦‚ä¸‹:

```python
def get_text(self, separator="", strip=False,
             types=(NavigableString, CData)):
    """
        Get all child strings, concatenated using the given separator.
        """
    return separator.join([s for s in self._all_strings(
        strip, types=types)])
```

è¯¥æ–¹æ³•ä¼šå°†æ–‡æ¡£æˆ– tag ä¸­çš„æ‰€æœ‰æ–‡æœ¬åˆå¹¶ä¸ºä¸€ä¸ª Unicode å­—ç¬¦ä¸²ï¼Œå¹¶è¿”å›è¯¥å­—ç¬¦ä¸²:

```python
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">\nI linked to <i>example.com</i>\n</a>'
soup = BeautifulSoup(markup, 'lxml')

print(soup.get_text())
print(soup.i.get_text())
```

è¾“å‡º:

```

I linked to example.com

example.com

```

*separator* å‚æ•°ç”¨äºè®¾ç½®åˆ†éš”ç¬¦:

```python
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">\nI linked to <i>example.com</i>\n</a>'
soup = BeautifulSoup(markup, 'lxml')

print(repr(soup.get_text('|')))
#> '\nI linked to |example.com|\n'
```

*strip* å‚æ•°ç”¨äºè®¾ç½®æ˜¯å¦å‰¥ç¦»æ¯æ®µæ–‡æœ¬å¼€å¤´å’Œç»“å°¾å¤„çš„ç©ºç™½ç¬¦(*whitespace*)ï¼š

```python
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">\nI linked to <i>example.com</i>\n</a>'
soup = BeautifulSoup(markup, 'lxml')

print(repr(soup.get_text('|', strip=True)))
#> 'I linked to|example.com'
```

å¦‚æœéœ€è¦è‡ªå·±å¤„ç†æ–‡æœ¬ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ [.stripped_strings](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#string-generators) ç”Ÿæˆå™¨ï¼Œå®ƒä¼šä¸ºæˆ‘ä»¬é€ä¸€æå–æ¯æ®µæ–‡æœ¬:

```python
from bs4 import BeautifulSoup
markup = '<a href="http://example.com/">\nI linked to <i>example.com</i>\n</a>'
soup = BeautifulSoup(markup, 'lxml')

print([text for text in soup.stripped_strings])
#> ['I linked to', 'example.com']
```

#### .text

`text` å­—æ®µçš„æºä»£ç å¦‚ä¸‹:

```python
text = property(get_text)
```



